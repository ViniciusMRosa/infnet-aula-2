{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Necessário para exibir as imagens no notebook.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. O Spambase Data Set\n",
    "\n",
    "O Spambase data set está disponível no site da [UCI](https://archive.ics.uci.edu/ml/datasets/Spambase).O conjunto de dados comtém 4600 mensagens de email classificadas como spam ou não-spam, e o nosso objetivo é construir um classificador que seja capaz de distinguir, com uma boa precisão, um spam de um email normal.\n",
    "\n",
    "Nessa base de dados, cada email foi convertido em uma sequência de 58 valores numericos (58 atributos), onde:\n",
    "\n",
    "- [0-47] 48 palavras mais citadas nos emails, onde cada valor representa a probabilidade da palavra ser encontrada no email (*[número de ocorrências]/[total de palavras] x 100 *);\n",
    "- [48-53] 6 caracteres mais frequentes nos emails, e cada valor representa a probabiidade do caracter ser encontrado no email (*[número de ocorrências]/[total de caracteres] x 100*);\n",
    "- [54] comprimento médio das palavras escritas em caixa alta;\n",
    "- [55] comprimento da maior palavra escritas em caixa alta;\n",
    "- [56] total de letras em maiúsculo no email.\n",
    "- [57] a classe do email: 1 (spam) ou 0 (não-spam).\n",
    "\n",
    "\\**Para mais informações visite o notebbok da [aula anterior](https://github.com/fernandus16/infnet-aula-1/blob/master/Spambase%20-%20Introdu%C3%A7%C3%A3o.ipynb).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O KNN\n",
    "\n",
    "http://www.inf.ufg.br/mestrado/sites/www.inf.ufg.br.mestrado/files/uploads/Dissertacoes/Fernando%20Chagas.pdf\n",
    "\n",
    "O método dos k vizinhos mais similares tem sido aplicado na solução de problemas desde o início das pesquisas nessa área e, apesar de simples, tem se mostrado um dos métodos mais eficazes já propostos. Para classificar um documento *d*, ainda não classificado (denominado documento de teste), esse método tradicionalmente realiza as seguintes atividades:\n",
    "1. A similaridade entre o documento de teste *d* e cada um dos documentos que foram previamente classificados por um especialista (documentos de treino) é calculada utilizando alguma medida de similaridade entre documentos;\n",
    "2. Os k documentos de treino mais similares ao documento *d* são selecionados.\n",
    "3. O documento *d* é classificado em determinada categoria de acordo com algum critério de agrupamento dos k vizinhos mais próximos selecionados na etapa anterior (por exemplo, a categoria que possuir a maioria dos k vizinhos mais próximos ao documento de teste *d*).\n",
    "\n",
    "\n",
    "O critério de similaridade é um aspecto que possui grande influência no desempenho do método kNN. Esse critério é composto pela **medida de similaridade, ou função de distância** (conforme a primeira atividade realizada pelo método kNN), e **pelo critério de seleção** (conforme a segunda atividade realizada pelo método kNN). **O critério de seleção determina a forma de escolha dos k vizinhos de um documento de teste d**. Por exemplo, selecionar os 5 documentos de treino mais similares ao documento de teste d é um critério de seleção\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "## Leitura dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# Lendo csv\n",
    "csv_data = pd.read_csv(\"data/spambase.csv\")\n",
    "\n",
    "# Copiando os dados do csv\n",
    "data = csv_data.values.copy()\n",
    "\n",
    "# Embaralhando os dados para garantir aleatoriedade entre as amostras\n",
    "# np.random.shuffle(data)\n",
    "\n",
    "# Separando atributos de classes\n",
    "x = data[:, :-1]  # x tem apenas valores entre a primeira e penúltima coluna\n",
    "y = data[:, -1]  # y tem os valores da última coluna\n",
    "\n",
    "# 70% dos dados serão utilizados para treinamento e 30% para o teste\n",
    "# A divisão será estratificada, serão mantidas as proporções de spam e não spam em cada grupo\n",
    "x_treino, x_teste, y_treino, y_teste = train_test_split(x, y, train_size=0.7, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicando o K-Means com Sklearn\n",
    "\n",
    "#### Critério de seleção dos k vizinhos:\n",
    " - ‘uniform’: todos os vizinhos tem pesos iguais;\n",
    " - ‘distance’: os mais próximos tem maior peso. O vizinho mais próximo tem uma influência maior sobre a decisão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisão do KNN:  0.748161764706\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "\n",
    "k = 10\n",
    "knn_clf = KNeighborsClassifier(k, weights='distance')\n",
    "# Treinamento\n",
    "knn_clf.fit(x_treino, y_treino)\n",
    "# Predição\n",
    "y_knn_pred = knn_clf.predict(x_teste)\n",
    "\n",
    "# precision_score = tp / (tp + fp) onde tp ee o numero verdadeiro positivo fp, falsos positivos.\n",
    "print u\"Precisão do KNN: \", precision_score(y_knn_pred, y_teste, average='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fazendo um comparativos com os métodos apresentados na aula anterior\n",
    "\n",
    "\n",
    "Primeiro, uma função para executar e avaliar os métodos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def get_clf_precision(clf):\n",
    "\n",
    "    start_time = datetime.now()\n",
    "    clf.fit(x_treino, y_treino)\n",
    "    fit_time = datetime.now() - start_time\n",
    "    print \"Fit time: \", fit_time.microseconds\n",
    "    \n",
    "    # Predição\n",
    "    y_pred = clf.predict(x_teste)\n",
    "    pred_time = datetime.now() - start_time - fit_time\n",
    "    print \"Pred time: \", pred_time.microseconds\n",
    "    \n",
    "    return precision_score(y_pred, y_teste, average='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Executando:\n",
    " - KNN;\n",
    " - Bernoulli Naive Bayes;\n",
    " - Multinomial Naive Bayes;\n",
    " - Árvore de Decisão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time:  9158\n",
      "Pred time:  57708\n",
      "Classificador KNN - precisão de 0.748161764706\n",
      "Fit time:  56385\n",
      "Pred time:  1873\n",
      "Classificador Bernoulli Naive Bayes - precisão de 0.819852941176\n",
      "Fit time:  39895\n",
      "Pred time:  1086\n",
      "Classificador Árvore de Decisão - precisão de 0.845588235294\n",
      "Fit time:  2022\n",
      "Pred time:  328\n",
      "Classificador Multinomial Naive Bayes - precisão de 0.672794117647\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf_list = {\n",
    "    u\"KNN\": KNeighborsClassifier(k, weights='distance'),\n",
    "    u\"Bernoulli Naive Bayes\": BernoulliNB(),\n",
    "    u\"Multinomial Naive Bayes\": MultinomialNB(),\n",
    "    u\"Árvore de Decisão\": DecisionTreeClassifier(criterion=\"gini\", random_state=9, max_depth=9),\n",
    "}\n",
    "\n",
    "for clf_name, clf in clf_list.iteritems():\n",
    "    print u\"Classificador %s - precisão de %s\" % (clf_name, get_clf_precision(clf))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
