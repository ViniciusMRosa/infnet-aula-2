{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Necessário para exibir as imagens no notebook.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. O Spambase Data Set\n",
    "\n",
    "O Spambase data set está disponível no site da [UCI](https://archive.ics.uci.edu/ml/datasets/Spambase).O conjunto de dados comtém 4600 mensagens de email classificadas como spam ou não-spam, e o nosso objetivo é construir um classificador que seja capaz de distinguir, com uma boa precisão, um spam de um email normal.\n",
    "\n",
    "Nessa base de dados, cada email foi convertido em uma sequência de 58 valores numericos (58 atributos), onde:\n",
    "\n",
    "- [0-47] 48 palavras mais citadas nos emails, onde cada valor representa a probabilidade da palavra ser encontrada no email (*[número de ocorrências]/[total de palavras] x 100 *);\n",
    "- [48-53] 6 caracteres mais frequentes nos emails, e cada valor representa a probabiidade do caracter ser encontrado no email (*[número de ocorrências]/[total de caracteres] x 100*);\n",
    "- [54] comprimento médio das palavras escritas em caixa alta;\n",
    "- [55] comprimento da maior palavra escritas em caixa alta;\n",
    "- [56] total de letras em maiúsculo no email.\n",
    "- [57] a classe do email: 1 (spam) ou 0 (não-spam).\n",
    "\n",
    "\\**Para mais informações visite o notebbok da [aula anterior](https://github.com/fernandus16/infnet-aula-1/blob/master/Spambase%20-%20Introdu%C3%A7%C3%A3o.ipynb).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O KNN\n",
    "\n",
    "http://www.inf.ufg.br/mestrado/sites/www.inf.ufg.br.mestrado/files/uploads/Dissertacoes/Fernando%20Chagas.pdf\n",
    "\n",
    "O método dos k vizinhos mais similares (kNN, do inglês k nearest neighbors)\n",
    "tem sido aplicado na solução de problemas de CAT desde o início das pesquisas nessa\n",
    "área e, apesar de simples, tem se mostrado um dos métodos mais eficazes já propostos\n",
    "[134]. Para classificar um documento d, ainda não classificado (denominado documento\n",
    "de teste), esse método tradicionalmente realiza as seguintes atividades:\n",
    "1. A similaridade entre o documento de teste d e cada um dos documentos que foram\n",
    "previamente classificados por um especialista (denominados documentos de treino) é calculada utilizando alguma medida de similaridade entre documentos, tal como\n",
    "a medida do cosseno (Seção 3.1.3) [107].\n",
    "2. Os k documentos de treino mais similares ao documento d são selecionados (k\n",
    "vizinhos mais próximos).\n",
    "3. O documento d é classificado em determinada categoria de acordo com algum\n",
    "critério de agrupamento dos k vizinhos mais próximos selecionados na etapa\n",
    "anterior (por exemplo, a categoria que possuir a maioria dos k vizinhos mais\n",
    "próximos ao documento de teste d).\n",
    "\n",
    "\n",
    "O critério de similaridade é um aspecto que possui grande influência no desempenho\n",
    "do método kNN [113]. Esse critério é composto pela medida de similaridade, ou\n",
    "função de distância (conforme a primeira atividade realizada pelo método kNN), e pelo\n",
    "critério de seleção (conforme a segunda atividade realizada pelo método kNN). O critério\n",
    "de seleção determina a forma de escolha dos k vizinhos de um documento de teste d. Por\n",
    "exemplo, selecionar os 5 documentos de treino mais similares ao documento de teste d é\n",
    "um critério de seleção\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "## Leitura dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# Lendo csv\n",
    "csv_data = pd.read_csv(\"data/spambase.csv\")\n",
    "\n",
    "# Copiando os dados do csv\n",
    "data = csv_data.values.copy()\n",
    "\n",
    "# Embaralhando os dados para garantir aleatoriedade entre as amostras\n",
    "# np.random.shuffle(data)\n",
    "\n",
    "# Separando atributos de classes\n",
    "x = data[:, :-1]  # x tem apenas valores entre a primeira e penúltima coluna\n",
    "y = data[:, -1]  # y tem os valores da última coluna\n",
    "\n",
    "# 70% dos dados serão utilizados para treinamento e 30% para o teste\n",
    "# A divisão será estratificada, serão mantidas as proporções de spam e não spam em cada grupo\n",
    "x_treino, x_teste, y_treino, y_teste = train_test_split(x, y, train_size=0.7, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "weight function used in prediction. Possible values:\n",
    "‘uniform’ : uniform weights. All points in each neighborhood are weighted equally.\n",
    "‘distance’ : weight points by the inverse of their distance. in this case, closer neighbors of a query point will have a greater influence than neighbors which are further away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisão do KNN:  0.792279411765\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "\n",
    "k = 10\n",
    "knn_clf = KNeighborsClassifier(k, weights='distance')\n",
    "# Treinamento\n",
    "knn_clf.fit(x_treino, y_treino)\n",
    "# Predição\n",
    "y_knn_pred = knn_clf.predict(x_teste)\n",
    "\n",
    "# precision_score = tp / (tp + fp) onde tp ee o numero verdadeiro positivo fp, falsos positivos.\n",
    "print u\"Precisão do KNN: \", precision_score(y_knn_pred, y_teste, average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def get_clf_precision(clf):\n",
    "\n",
    "    start_time = datetime.now()\n",
    "    clf.fit(x_treino, y_treino)\n",
    "    fit_time = datetime.now() - start_time\n",
    "    print \"Fit time: \", fit_time.microseconds\n",
    "    \n",
    "    # Predição\n",
    "    y_pred = clf.predict(x_teste)\n",
    "    pred_time = datetime.now() - start_time - fit_time\n",
    "    print \"Pred time: \", pred_time.microseconds\n",
    "    \n",
    "    return precision_score(y_pred, y_teste, average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time:  6822\n",
      "Pred time:  50684\n",
      "Classificador KNN - precisão de 0.792279411765\n",
      "Fit time:  4312\n",
      "Pred time:  1300\n",
      "Classificador Bernoulli Naive Bayes - precisão de 0.806985294118\n",
      "Fit time:  36120\n",
      "Pred time:  474\n",
      "Classificador Árvore de Decisão - precisão de 0.887867647059\n",
      "Fit time:  2020\n",
      "Pred time:  240\n",
      "Classificador Multinomial Naive Bayes - precisão de 0.724264705882\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf_list = {\n",
    "    u\"KNN\": KNeighborsClassifier(k, weights='distance'),\n",
    "    u\"Bernoulli Naive Bayes\": BernoulliNB(),\n",
    "    u\"Multinomial Naive Bayes\": MultinomialNB(),\n",
    "    u\"Árvore de Decisão\": DecisionTreeClassifier(criterion=\"gini\", random_state=9, max_depth=9),\n",
    "}\n",
    "\n",
    "for clf_name, clf in clf_list.iteritems():\n",
    "    print u\"Classificador %s - precisão de %s\" % (clf_name, get_clf_precision(clf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
